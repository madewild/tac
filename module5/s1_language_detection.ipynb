{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La détection de langue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons ici la librairie langid:\n",
    "    \n",
    "https://pypi.org/project/langid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import langid\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcer l'algorithme à ne détecter que du Français et du Néerlandais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "langid.set_languages(['fr', 'nl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lister tous les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2827 TXT files found\n"
     ]
    }
   ],
   "source": [
    "root = \"../data/txt/\"\n",
    "txts = os.listdir(root)\n",
    "print(f\"{len(txts)} TXT files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détecter la langue pour tous les documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons lire chaque fichier, détecter la langue, et incrémenter `lang_dict` lorsqu'une langue est détectée.\n",
    "\n",
    "**Important** : pour détecter les langues sur tous les documents, mettez `limit = None` ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 2000\n",
    "# limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dict = defaultdict(int)\n",
    "txts = txts[:limit] if limit else texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 document(s) processed...\n",
      "100 document(s) processed...\n",
      "150 document(s) processed...\n",
      "200 document(s) processed...\n",
      "Bxl_1869_Tome_I1_Part_4.txt contains only 4 characters, treating as unknown\n",
      "250 document(s) processed...\n",
      "300 document(s) processed...\n",
      "350 document(s) processed...\n",
      "400 document(s) processed...\n",
      "450 document(s) processed...\n",
      "500 document(s) processed...\n",
      "550 document(s) processed...\n",
      "600 document(s) processed...\n",
      "650 document(s) processed...\n",
      "700 document(s) processed...\n",
      "750 document(s) processed...\n",
      "Bxl_1903_Tome_I2_2_Part_12.txt contains only 19 characters, treating as unknown\n",
      "800 document(s) processed...\n",
      "850 document(s) processed...\n",
      "900 document(s) processed...\n",
      "950 document(s) processed...\n",
      "1000 document(s) processed...\n",
      "1050 document(s) processed...\n",
      "1100 document(s) processed...\n",
      "1150 document(s) processed...\n",
      "Bxl_1925_Tome_II1_2_Part_8.txt contains only 9 characters, treating as unknown\n",
      "1200 document(s) processed...\n",
      "1250 document(s) processed...\n",
      "Bxl_1929_Tome_I_Part_10.txt contains only 1 characters, treating as unknown\n",
      "1300 document(s) processed...\n",
      "1350 document(s) processed...\n",
      "1400 document(s) processed...\n",
      "1450 document(s) processed...\n",
      "Bxl_1946_Tome_II_Part_14.txt contains only 1 characters, treating as unknown\n",
      "1500 document(s) processed...\n",
      "1550 document(s) processed...\n",
      "1600 document(s) processed...\n",
      "Bxl_1952_Tome_I_Part_9.txt contains only 2 characters, treating as unknown\n",
      "1650 document(s) processed...\n",
      "1700 document(s) processed...\n",
      "1750 document(s) processed...\n",
      "Bxl_1957_Tome_II2_Part_10.txt contains only 9 characters, treating as unknown\n",
      "1800 document(s) processed...\n",
      "Bxl_1957_Tome_I_Part_12.txt contains only 2 characters, treating as unknown\n",
      "Bxl_1958_Tome_RptAn_Part_10.txt contains only 9 characters, treating as unknown\n",
      "1850 document(s) processed...\n",
      "1900 document(s) processed...\n",
      "1950 document(s) processed...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for i, txt in enumerate(sorted(txts)):\n",
    "    if txt.endswith(\"txt\"):\n",
    "        if i % 50 == 0:\n",
    "            print(f'{i} document(s) processed...')\n",
    "        text = open(os.path.join(root, txt)).read()\n",
    "        text_length = len(text)\n",
    "        if text_length > 20:\n",
    "            lang, conf = langid.classify(text)\n",
    "            lang_dict[lang] += 1\n",
    "        else:\n",
    "            print(f\"{txt} contains only {text_length} characters, treating as unknown\")\n",
    "            lang_dict['n/a'] += 1\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher le nombre de documents par langue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\t1989\n",
      "None\t9\n",
      "Dutch\t1\n"
     ]
    }
   ],
   "source": [
    "for lang_code, nb_docs in lang_dict.items():\n",
    "    language = pycountry.languages.get(alpha_2=lang_code)\n",
    "    try:\n",
    "        lang_name = language.name\n",
    "    except AttributeError:\n",
    "        lang_name = language\n",
    "    print(f\"{lang_name}\\t{nb_docs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
